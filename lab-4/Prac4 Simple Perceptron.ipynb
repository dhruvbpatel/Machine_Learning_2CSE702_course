{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # TODO: Set weight1, weight2, and bias\n",
    "# weight1 = 1.0\n",
    "# weight2 = 1.0\n",
    "# bias = -0.501\n",
    "\n",
    "# # DON'T CHANGE ANYTHING BELOW\n",
    "# # Inputs and outputs\n",
    "# test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "# correct_outputs = [False, True, True, True]\n",
    "# outputs = []\n",
    "\n",
    "# # Generate and check output\n",
    "# for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "#     linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "#     output = int(linear_combination >= 0)\n",
    "#     is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "#     outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# # Print output\n",
    "# num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "# output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "# if not num_wrong:\n",
    "#     print('Nice!  You got it all correct.\\n')\n",
    "# else:\n",
    "#     print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "# print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Simple Perceptron Class for AND implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self,inputs,iterations=10,learning_rate = 0.01):\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(inputs+1)\n",
    "        \n",
    "    def predict(self,inputs):\n",
    "        summ = np.dot(inputs,self.weights[1:])+self.weights[0]\n",
    "        if summ>0:\n",
    "            activation =1\n",
    "        else:\n",
    "            activation = 0\n",
    "        return activation\n",
    "        \n",
    "    \n",
    "    def train(self,training_inputs,labels):\n",
    "        for i in range(self.iterations):\n",
    "            for inputs,label in zip(training_inputs,labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                \n",
    "                self.weights[1:] += self.learning_rate*(label-prediction)*inputs\n",
    "                self.weights[0] += self.learning_rate*(label-prediction)\n",
    "                \n",
    "            print(\"weights after iteration {} :{},new bias: {} \".format(i,self.weights[1:],self.weights[0]))\n",
    "        print(\"Final Weights :{},new bias: {} \".format(self.weights[1:],self.weights[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = []\n",
    "training_inputs.append(np.array([1, 1]))\n",
    "training_inputs.append(np.array([1, 0]))\n",
    "training_inputs.append(np.array([0, 1]))\n",
    "training_inputs.append(np.array([0, 0]))\n",
    "\n",
    "#Adding Labels\n",
    "labels = np.array([1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights after iteration 0 :[0. 0.],new bias: -0.01 \n",
      "weights after iteration 1 :[0.   0.01],new bias: -0.01 \n",
      "weights after iteration 2 :[0.   0.01],new bias: -0.02 \n",
      "weights after iteration 3 :[0.01 0.01],new bias: -0.02 \n",
      "weights after iteration 4 :[0.01 0.02],new bias: -0.02 \n",
      "weights after iteration 5 :[0.01 0.02],new bias: -0.02 \n",
      "weights after iteration 6 :[0.01 0.02],new bias: -0.02 \n",
      "weights after iteration 7 :[0.01 0.02],new bias: -0.02 \n",
      "weights after iteration 8 :[0.01 0.02],new bias: -0.02 \n",
      "weights after iteration 9 :[0.01 0.02],new bias: -0.02 \n",
      "Final Weights :[0.01 0.02],new bias: -0.02 \n"
     ]
    }
   ],
   "source": [
    "perceptron.train(training_inputs,labels)  ## training our perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([1,1])  # testing our perceptron and it is working perfectly\n",
    "print(perceptron.predict(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([1,0])\n",
    "print(perceptron.predict(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02,  0.01,  0.02])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Perceptron_OR(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, threshold=10, learning_rate=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.ones(no_of_inputs + 1)  ## including bias 2+1  = 3\n",
    "           \n",
    "    #Make prediction, here we are using a simple threshold of greater than zero for our activation function\n",
    "    def predict(self, inputs):\n",
    "        summ = np.dot(inputs, self.weights[1:]) + self.weights[0]  # self.weights[0] is considering bias\n",
    "        if summ >= 0:\n",
    "            activation = 1  \n",
    "        else:\n",
    "            activation = 0            \n",
    "        return activation\n",
    "    \n",
    "    def train(self, training_inputs, labels):\n",
    "        for i in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)\n",
    "            print(\"weights after iteration {} :{},new bias: {} \".format(i,self.weights[1:],self.weights[0]))\n",
    "        print(\"Final Weights :{},new bias: {} \".format(self.weights[1:],self.weights[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_or_gate= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = []\n",
    "training_inputs.append(np.array([0,0]))\n",
    "training_inputs.append(np.array([0,1]))\n",
    "training_inputs.append(np.array([1,0]))\n",
    "training_inputs.append(np.array([1,1]))\n",
    "\n",
    "#Adding Labels\n",
    "labels_or = np.array([0,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_or = Perceptron_OR(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights after iteration 0 :[1. 1.],new bias: 0.99 \n",
      "weights after iteration 1 :[1. 1.],new bias: 0.98 \n",
      "weights after iteration 2 :[1. 1.],new bias: 0.97 \n",
      "weights after iteration 3 :[1. 1.],new bias: 0.96 \n",
      "weights after iteration 4 :[1. 1.],new bias: 0.95 \n",
      "weights after iteration 5 :[1. 1.],new bias: 0.94 \n",
      "weights after iteration 6 :[1. 1.],new bias: 0.9299999999999999 \n",
      "weights after iteration 7 :[1. 1.],new bias: 0.9199999999999999 \n",
      "weights after iteration 8 :[1. 1.],new bias: 0.9099999999999999 \n",
      "weights after iteration 9 :[1. 1.],new bias: 0.8999999999999999 \n",
      "Final Weights :[1. 1.],new bias: 0.8999999999999999 \n"
     ]
    }
   ],
   "source": [
    "perceptron_or.train(training_inputs,labels_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([1,0])\n",
    "print(perceptron.predict(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights: [0.61147471 0.54163914] [0.86336028 0.05129989]\n",
      "Initial hidden biases: [0.18525641 0.34895599]\n",
      "Initial output weights: [0.02654494] [0.99419315]\n",
      "Initial output biases: [0.95781594]\n",
      "Final hidden weights: [2.73100448 4.06500869] [2.84785377 3.982446  ]\n",
      "Final hidden bias: [-1.58970364 -2.17452362]\n",
      "Final output weights: [3.57458172] [6.18610858]\n",
      "Final output bias: [-4.35501231]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.04237271] [0.97686554] [0.97654002] [0.99514686]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "#np.random.seed(0)\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[1]])\n",
    "\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "    #Forward Propagation\n",
    "    hidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "    hidden_layer_activation += hidden_bias\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "    output_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "    output_layer_activation += output_bias\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "    #Backpropagation\n",
    "    error = expected_output - predicted_output\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    \n",
    "    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    #Updating Weights and Biases\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "    hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "    hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85683785, 0.4696105 ],\n",
       "       [0.28039111, 0.61509522]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(size=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
